import streamlit as st
import pandas as pd
import re
import io
from typing import List, Dict, Tuple, Optional
import docx

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –ß–¢–ï–ù–ò–Ø –§–ê–ô–õ–û–í
# =============================================================================

def read_uploaded_file(file):
    """
    –ß–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ —Ç–∏–ø–∞
    """
    try:
        file.seek(0)
        
        if file.name.endswith('.docx'):
            doc = docx.Document(file)
            full_text = []
            
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    full_text.append(paragraph.text)
            
            for table in doc.tables:
                for row in table.rows:
                    row_text = []
                    for cell in row.cells:
                        if cell.text.strip():
                            row_text.append(cell.text)
                    if row_text:
                        full_text.append(" | ".join(row_text))
            
            return "\n".join(full_text)
        else:
            return file.getvalue().decode("utf-8")
            
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {file.name}: {str(e)}")
        return None

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–•
# =============================================================================

def parse_correct_order(file_content: str) -> List[Dict]:
    """
    –ü–∞—Ä—Å–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞ —Å –≤—ã—Ä–µ–∑–∫–∞–º–∏
    """
    if not file_content:
        return []
        
    lines = file_content.split('\n')
    correct_samples = []
    
    for line in lines:
        line = line.strip()
        
        if re.match(r'^[-]+$', line) or not line:
            continue
            
        clean_line = re.sub(r'\[(.*?)\]\{\.mark\}', r'\1', line)
        
        match = re.match(r'^\s*(\d+)\s+(.+)$', clean_line)
        if match:
            sample_number = int(match.group(1))
            sample_name = match.group(2).strip()
            
            # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
            parsed_info = parse_structured_name(sample_name)
            
            correct_samples.append({
                'order': sample_number,
                'correct_name': sample_name,
                'parsed': parsed_info
            })
    
    return correct_samples

def parse_structured_name(name: str) -> Dict:
    """
    –ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –æ–±—Ä–∞–∑—Ü–∞
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: {surface, number, letter, original}
    """
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
    normalized = name.strip()
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)
    patterns_correct = [
        # –≠–ü–ö(1,–ê), –ö–ü–ü –í–î(50,–ê), –ö–ü–ü –ù–î-1(19,–ê)
        r'([–∞-—è–ê-–Ø\s-]+)\((\d+),\s*([–∞-—è–ê-–Ø])\)',
    ]
    
    for pattern in patterns_correct:
        match = re.search(pattern, normalized)
        if match:
            surface = match.group(1).strip()
            number = match.group(2)
            letter = match.group(3).upper()
            
            return {
                'surface': surface,
                'number': number,
                'letter': letter,
                'original': normalized,
                'type': 'structured'
            }
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –∏–∑ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    patterns_analysis = [
        # –ù–ì –®–ü–ü 4, –ù–ë –®–ü–ü 6
        r'([–∞-—è–ê-–Ø]{2})\s+([–∞-—è–ê-–Ø]+)\s+(\d+)',
        # –ö–ü–ü –í–î 2, —Ç—Ä—É–±–∞ 13
        r'([–∞-—è–ê-–Ø\s-]+)\s+(\d+)[,\s]+\S*\s*(\d+)',
        # –ö–ü–ü –í–î 2, —Ç—Ä—É–±–∞ 13 (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
        r'([–∞-—è–ê-–Ø\s-]+?)\s+\d+[,\s]+\S*\s*(\d+)',
        # –ü—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ –≤ –∫–æ–Ω—Ü–µ
        r'(.+?)\s+(\d+)$',
    ]
    
    for pattern in patterns_analysis:
        match = re.search(pattern, normalized)
        if match:
            surface = match.group(1).strip()
            number = match.group(2) if len(match.groups()) >= 2 else None
            letter = None  # –í —Ö–∏–º–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ –±—É–∫–≤–∞ –æ–±—ã—á–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–∞
            
            return {
                'surface': surface,
                'number': number,
                'letter': letter,
                'original': normalized,
                'type': 'analysis'
            }
    
    # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å
    return {
        'surface': normalized,
        'number': None,
        'letter': None,
        'original': normalized,
        'type': 'unknown'
    }

def normalize_surface_name(surface: str) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –Ω–∞–≥—Ä–µ–≤–∞ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
    """
    # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    normalized = re.sub(r'\s+', ' ', surface.strip().lower())
    
    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π
    surface_mappings = {
        r'–∫–ø–ø\s*–≤–¥': '–ö–ü–ü –í–î',
        r'–∫–ø–ø\s*–Ω–¥-1': '–ö–ü–ü –ù–î-1',
        r'–∫–ø–ø\s*–Ω–¥-2': '–ö–ü–ü –ù–î-2',
        r'–∫–ø–ø\s*–Ω–¥': '–ö–ü–ü –ù–î',
        r'—à–ø–ø': '–®–ü–ü',
        r'—ç–ø–∫': '–≠–ü–ö',
        r'–ø—Å\s*–∫—à': '–ü–° –ö–®',
    }
    
    for pattern, standard in surface_mappings.items():
        if re.search(pattern, normalized):
            return standard
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª –≤ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–º –≤–∏–¥–µ
    return normalized.title()

def parse_chemical_tables_improved(file_content: str) -> Dict[str, List[Dict]]:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    """
    if not file_content:
        return {}
    
    lines = file_content.split('\n')
    tables = {}
    current_steel_grade = None
    current_table = []
    
    for line in lines:
        line = line.strip()
        
        # –ò—â–µ–º –º–∞—Ä–∫—É —Å—Ç–∞–ª–∏
        steel_match = re.search(r'–ú–∞—Ä–∫–∞ —Å—Ç–∞–ª–∏:\s*([^\n]+)', line, re.IGNORECASE)
        if steel_match:
            if current_steel_grade and current_table:
                tables[current_steel_grade] = current_table
                current_table = []
            current_steel_grade = steel_match.group(1).strip()
            continue
        
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å—Ç—Ä–æ–∫–∏
        if any(x in line for x in ['–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –¢–£', '14-3–†-55-2001', '---', '###']):
            continue
        
        # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –æ–±—Ä–∞–∑—Ü–∞–º–∏
        if current_steel_grade and re.match(r'^\s*\d+\s+[^\d]', line):
            # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–æ–±–µ–ª–∞–º
            parts = re.split(r'\s{2,}', line)
            if len(parts) >= 2:
                sample_name = parts[1]
                measurements = parts[2:] if len(parts) > 2 else []
                
                # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                parsed_info = parse_structured_name(sample_name)
                
                sample_data = {
                    'original_name': sample_name,
                    'measurements': measurements,
                    'parsed': parsed_info
                }
                current_table.append(sample_data)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Ç–∞–±–ª–∏—Ü—É
    if current_steel_grade and current_table:
        tables[current_steel_grade] = current_table
    
    return tables

def find_best_match(analysis_sample: Dict, correct_samples: List[Dict]) -> Optional[Dict]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–ª—É—á—à–µ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–ª—è –æ–±—Ä–∞–∑—Ü–∞ –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ —Å—Ä–µ–¥–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤
    """
    analysis_parsed = analysis_sample['parsed']
    analysis_surface = normalize_surface_name(analysis_parsed['surface'])
    analysis_number = analysis_parsed['number']
    
    best_match = None
    best_score = 0
    
    for correct_sample in correct_samples:
        correct_parsed = correct_sample['parsed']
        correct_surface = normalize_surface_name(correct_parsed['surface'])
        correct_number = correct_parsed['number']
        correct_letter = correct_parsed['letter']
        
        score = 0
        
        # 1. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –Ω–∞–≥—Ä–µ–≤–∞ (—Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π –∫—Ä–∏—Ç–µ—Ä–∏–π)
        if analysis_surface == correct_surface:
            score += 100
        elif analysis_surface in correct_surface or correct_surface in analysis_surface:
            score += 50  # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # 2. –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–æ–º–µ—Ä–∞ —Ç—Ä—É–±—ã
        if analysis_number and correct_number and analysis_number == correct_number:
            score += 50
        
        # 3. –ï—Å–ª–∏ –µ—Å—Ç—å –±—É–∫–≤–∞ –≤ –∞–Ω–∞–ª–∏–∑–µ, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        if analysis_parsed['letter'] and correct_letter and analysis_parsed['letter'] == correct_letter:
            score += 25
        
        # 4. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è —á–∞—Å—Ç–∏—á–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        if analysis_number and correct_number and analysis_number in correct_number:
            score += 10
        if correct_number and analysis_number and correct_number in analysis_number:
            score += 10
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ª—É—á—à–∏–π –º–∞—Ç—á
        if score > best_score:
            best_score = score
            best_match = correct_sample
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞—Ç—á —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ score –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –≤—ã—Å–æ–∫
    return best_match if best_score >= 50 else None

def match_samples_improved(analysis_samples: List[Dict], correct_samples: List[Dict]) -> List[Dict]:
    """
    –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—Ä–∞–∑—Ü–æ–≤
    """
    matched = []
    used_correct_indices = set()
    
    # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    for i, analysis_sample in enumerate(analysis_samples):
        best_match = find_best_match(analysis_sample, correct_samples)
        
        if best_match and best_match['order'] not in used_correct_indices:
            matched.append({
                'correct_name': best_match['correct_name'],
                'original_name': analysis_sample['original_name'],
                'measurements': analysis_sample['measurements'],
                'order': best_match['order'],
                'match_quality': 'exact',
                'analysis_surface': analysis_sample['parsed']['surface'],
                'correct_surface': best_match['parsed']['surface'],
                'analysis_number': analysis_sample['parsed']['number'],
                'correct_number': best_match['parsed']['number']
            })
            used_correct_indices.add(best_match['order'])
    
    # –í—Ç–æ—Ä–æ–π –ø—Ä–æ—Ö–æ–¥: —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–¥–ª—è –Ω–µ–ø–æ–¥–æ–±—Ä–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤)
    for i, analysis_sample in enumerate(analysis_samples):
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ
        if any(m['original_name'] == analysis_sample['original_name'] for m in matched):
            continue
        
        # –ò—â–µ–º —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        analysis_parsed = analysis_sample['parsed']
        analysis_surface = normalize_surface_name(analysis_parsed['surface'])
        analysis_number = analysis_parsed['number']
        
        for correct_sample in correct_samples:
            if correct_sample['order'] in used_correct_indices:
                continue
                
            correct_parsed = correct_sample['parsed']
            correct_surface = normalize_surface_name(correct_parsed['surface'])
            correct_number = correct_parsed['number']
            
            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏
            surface_match = (analysis_surface in correct_surface or 
                           correct_surface in analysis_surface or
                           any(word in correct_surface for word in analysis_surface.split()) or
                           any(word in analysis_surface for word in correct_surface.split()))
            
            # –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ –Ω–æ–º–µ—Ä—É
            number_match = (analysis_number and correct_number and 
                          (analysis_number in correct_number or correct_number in analysis_number))
            
            if surface_match and number_match:
                matched.append({
                    'correct_name': correct_sample['correct_name'],
                    'original_name': analysis_sample['original_name'],
                    'measurements': analysis_sample['measurements'],
                    'order': correct_sample['order'],
                    'match_quality': 'partial',
                    'analysis_surface': analysis_sample['parsed']['surface'],
                    'correct_surface': correct_sample['parsed']['surface'],
                    'analysis_number': analysis_sample['parsed']['number'],
                    'correct_number': correct_sample['parsed']['number']
                })
                used_correct_indices.add(correct_sample['order'])
                break
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ—Ä—è–¥–∫—É –∏–∑ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
    matched.sort(key=lambda x: x['order'])
    
    return matched

# =============================================================================
# STREAMLIT –ò–ù–¢–ï–†–§–ï–ô–°
# =============================================================================

st.set_page_config(
    page_title="–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞",
    page_icon="üî¨",
    layout="wide"
)

st.markdown("""
<style>
    .main-header { 
        font-size: 2.5rem; 
        color: #1f77b4; 
        text-align: center; 
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .match-exact { background-color: #d4edda !important; }
    .match-partial { background-color: #fff3cd !important; }
</style>
""", unsafe_allow_html=True)

def main():
    st.markdown('<div class="main-header">üî¨ –£–º–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞</div>', unsafe_allow_html=True)
    
    with st.expander("üìñ –ò–ù–°–¢–†–£–ö–¶–ò–Ø", expanded=False):
        st.markdown("""
        **–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∞:**
        1. **–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –Ω–∞–∑–≤–∞–Ω–∏–π**: –ü—Ä–æ–≥—Ä–∞–º–º–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —à–∏—Ñ—Ä –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –Ω–∞–≥—Ä–µ–≤–∞, –Ω–æ–º–µ—Ä —Ç—Ä—É–±—ã –∏ –∫–æ—Ä–ø—É—Å/–Ω–∏—Ç–∫—É
        2. **–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º**: 
           - –°–Ω–∞—á–∞–ª–∞ —Ç–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ –Ω–∞–≥—Ä–µ–≤–∞ –∏ –Ω–æ–º–µ—Ä—É
           - –ó–∞—Ç–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        3. **–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤**: –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
        
        **–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞–∑–≤–∞–Ω–∏–π:**
        - –®–∏—Ñ—Ä—ã –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π: –≠–ü–ö, –ü–° –ö–®, –ö–ü–ü –ù–î-1, –ö–ü–ü –ù–î-2, –ö–ü–ü –í–î, –®–ü–ü
        - –ù–æ–º–µ—Ä —Ç—Ä—É–±—ã: —á–∏—Å–ª–æ
        - –ö–æ—Ä–ø—É—Å/–Ω–∏—Ç–∫–∞: –ê, –ë, –í, –ì
        """)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìã –§–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º")
        correct_order_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –ø–æ—Ä—è–¥–∫–æ–º –æ–±—Ä–∞–∑—Ü–æ–≤",
            type=['txt', 'docx'],
            key="correct_order"
        )
        
        if correct_order_file:
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {correct_order_file.name}")
    
    with col2:
        st.subheader("üß™ –§–∞–π–ª —Å —Ö–∏–º–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º")
        chemical_analysis_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª —Å –∞–Ω–∞–ª–∏–∑–æ–º", 
            type=['txt', 'docx'],
            key="chemical_analysis"
        )
        
        if chemical_analysis_file:
            st.success(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω: {chemical_analysis_file.name}")
    
    # –ö–Ω–æ–ø–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if st.button("üöÄ –û–ë–†–ê–ë–û–¢–ê–¢–¨ –î–ê–ù–ù–´–ï", type="primary", use_container_width=True):
        if not correct_order_file or not chemical_analysis_file:
            st.error("‚ùå –ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–±–∞ —Ñ–∞–π–ª–∞")
            return
        
        try:
            # –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤
            with st.spinner("üìñ –ß–∏—Ç–∞—é —Ñ–∞–π–ª—ã..."):
                correct_order_content = read_uploaded_file(correct_order_file)
                chemical_analysis_content = read_uploaded_file(chemical_analysis_file)
            
            if not correct_order_content or not chemical_analysis_content:
                st.error("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤")
                return
            
            # –ü–∞—Ä—Å–∏–Ω–≥
            with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –Ω–∞–∑–≤–∞–Ω–∏–π..."):
                correct_samples = parse_correct_order(correct_order_content)
                chemical_tables = parse_chemical_tables_improved(chemical_analysis_content)
            
            if not correct_samples:
                st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –æ–±—Ä–∞–∑—Ü—ã –≤ —Ñ–∞–π–ª–µ –ø–æ—Ä—è–¥–∫–∞")
                return
                
            if not chemical_tables:
                st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ç–∞–±–ª–∏—Ü—ã –∞–Ω–∞–ª–∏–∑–∞")
                return
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏—è—Ö
            st.subheader("üîç –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –ù–ê–ó–í–ê–ù–ò–ô")
            
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã
            st.write("**–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ–±—Ä–∞–∑—Ü—ã (—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ):**")
            correct_data = []
            for sample in correct_samples:
                parsed = sample['parsed']
                correct_data.append({
                    '‚Ññ': sample['order'],
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': sample['correct_name'],
                    '–ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å': parsed['surface'],
                    '–ù–æ–º–µ—Ä': parsed['number'],
                    '–ö–æ—Ä–ø—É—Å': parsed['letter']
                })
            st.dataframe(pd.DataFrame(correct_data), use_container_width=True)
            
            # –û–±—Ä–∞–∑—Ü—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
            all_analysis_samples = []
            for steel_grade, samples in chemical_tables.items():
                for sample in samples:
                    all_analysis_samples.append(sample)
            
            st.write("**–û–±—Ä–∞–∑—Ü—ã –∏–∑ —Ö–∏–º–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞:**")
            analysis_data = []
            for i, sample in enumerate(all_analysis_samples):
                parsed = sample['parsed']
                analysis_data.append({
                    '‚Ññ': i + 1,
                    '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': sample['original_name'],
                    '–ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å': parsed['surface'],
                    '–ù–æ–º–µ—Ä': parsed['number'],
                    '–ö–æ—Ä–ø—É—Å': parsed['letter'],
                    '–¢–∏–ø': parsed['type']
                })
            st.dataframe(pd.DataFrame(analysis_data), use_container_width=True)
            
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            with st.spinner("üîÑ –°–æ–ø–æ—Å—Ç–∞–≤–ª—è—é –æ–±—Ä–∞–∑—Ü—ã..."):
                all_matched_samples = []
                final_tables = {}
                
                for steel_grade, samples in chemical_tables.items():
                    matched_samples = match_samples_improved(samples, correct_samples)
                    all_matched_samples.extend(matched_samples)
                    
                    if matched_samples:
                        # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —ç—Ç–æ–π –º–∞—Ä–∫–∏ —Å—Ç–∞–ª–∏
                        if matched_samples and matched_samples[0]['measurements']:
                            num_measurements = len(matched_samples[0]['measurements'])
                            columns = ['‚Ññ', '–û–±—Ä–∞–∑–µ—Ü'] + [f'–ò–∑–º–µ—Ä–µ–Ω–∏–µ {i+1}' for i in range(num_measurements)]
                            
                            data = []
                            for i, sample in enumerate(matched_samples):
                                row = [i + 1, sample['correct_name']] + sample['measurements']
                                data.append(row)
                            
                            final_tables[steel_grade] = pd.DataFrame(data, columns=columns)
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            total_correct = len(correct_samples)
            total_analysis = sum(len(samples) for samples in chemical_tables.values())
            total_matched = len(all_matched_samples)
            matching_rate = (total_matched / total_analysis) * 100 if total_analysis > 0 else 0
            
            st.subheader("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø")
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–û–±—Ä–∞–∑—Ü–æ–≤ –≤ –ø–æ—Ä—è–¥–∫–µ", total_correct)
            with col2:
                st.metric("–û–±—Ä–∞–∑—Ü–æ–≤ –≤ –∞–Ω–∞–ª–∏–∑–µ", total_analysis)
            with col3:
                st.metric("–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–æ", f"{total_matched} ({matching_rate:.1f}%)")
            
            # –î–µ—Ç–∞–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
            if all_matched_samples:
                st.subheader("üîç –î–ï–¢–ê–õ–¨–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–Ø")
                
                match_data = []
                for sample in all_matched_samples:
                    match_data.append({
                        '‚Ññ –ø/–ø': sample['order'],
                        '–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': sample['correct_name'],
                        '–ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ': sample['original_name'],
                        '–ö–∞—á–µ—Å—Ç–≤–æ': sample['match_quality'],
                        '–ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å (–∞–Ω–∞–ª–∏–∑)': sample['analysis_surface'],
                        '–ü–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å (–ø—Ä–∞–≤–∏–ª—å–Ω–æ)': sample['correct_surface'],
                        '–ù–æ–º–µ—Ä (–∞–Ω–∞–ª–∏–∑)': sample['analysis_number'],
                        '–ù–æ–º–µ—Ä (–ø—Ä–∞–≤–∏–ª—å–Ω–æ)': sample['correct_number']
                    })
                
                match_df = pd.DataFrame(match_data)
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                def color_match_quality(val):
                    if val == 'exact':
                        return 'background-color: #d4edda'
                    elif val == 'partial':
                        return 'background-color: #fff3cd'
                    return ''
                
                styled_df = match_df.style.applymap(color_match_quality, subset=['–ö–∞—á–µ—Å—Ç–≤–æ'])
                st.dataframe(styled_df, use_container_width=True)
                
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                exact_matches = [m for m in all_matched_samples if m['match_quality'] == 'exact']
                partial_matches = [m for m in all_matched_samples if m['match_quality'] == 'partial']
                
                st.info(f"""
                **–ö–∞—á–µ—Å—Ç–≤–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:**
                - ‚úÖ –¢–æ—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {len(exact_matches)}
                - ‚ö†Ô∏è –ß–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {len(partial_matches)}
                """)
            
            # –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if final_tables:
                st.subheader("üìã –û–¢–°–û–†–¢–ò–†–û–í–ê–ù–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
                
                for steel_grade, table in final_tables.items():
                    with st.expander(f"üî© {steel_grade} ({len(table)} –æ–±—Ä–∞–∑—Ü–æ–≤)", expanded=True):
                        st.dataframe(table, use_container_width=True)
                        
                        # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ
                        excel_buffer = io.BytesIO()
                        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                            table.to_excel(writer, index=False, sheet_name=steel_grade[:30])
                        excel_buffer.seek(0)
                        
                        st.download_button(
                            label="üì• –°–∫–∞—á–∞—Ç—å Excel",
                            data=excel_buffer,
                            file_name=f"–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ_{steel_grade}.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            key=f"download_{steel_grade}"
                        )
                
                # –ü–∞–∫–µ—Ç–Ω–æ–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ
                if len(final_tables) > 1:
                    st.subheader("üíæ –ü–ê–ö–ï–¢–ù–û–ï –°–ö–ê–ß–ò–í–ê–ù–ò–ï")
                    excel_buffer_all = io.BytesIO()
                    with pd.ExcelWriter(excel_buffer_all, engine='openpyxl') as writer:
                        for steel_grade, table in final_tables.items():
                            table.to_excel(writer, index=False, sheet_name=steel_grade[:30])
                    excel_buffer_all.seek(0)
                    
                    st.download_button(
                        label="üì¶ –°–∫–∞—á–∞—Ç—å –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã (Excel)",
                        data=excel_buffer_all,
                        file_name="–≤—Å–µ_–æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ_—Ç–∞–±–ª–∏—Ü—ã.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                        key="download_all",
                        use_container_width=True
                    )
            else:
                st.warning("""
                ‚ö†Ô∏è **–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –æ–±—Ä–∞–∑—Ü—ã**
                
                **–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:**
                - –ù–∞–∑–≤–∞–Ω–∏—è –≤ —Ñ–∞–π–ª–∞—Ö —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è
                - –ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç—Å—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞–∑–≤–∞–Ω–∏–π
                - –ù—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∞–ª–≥–æ—Ä–∏—Ç–º–∞
                """)
                
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞: {str(e)}")
            import traceback
            st.code(traceback.format_exc())

if __name__ == "__main__":
    main()
